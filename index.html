<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sri Harsha Mudumba | ML Engineer</title>
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      margin: 0;
      padding: 0;
      background: linear-gradient(rgba(0,0,0,0.85), rgba(0,0,0,0.85)), url('ml.png') no-repeat center center fixed;
      background-size: cover;
      color: #f8f8f8;
      scroll-behavior: smooth;
    }

    header {
      background: rgba(0, 0, 0, 0.85);
      text-align: center;
      padding: 40px 20px;
      box-shadow: 0 4px 10px rgba(255, 255, 255, 0.1);
    }

    .typing {
      font-size: 20px;
      font-weight: bold;
      overflow: hidden;
      border-right: .15em solid #fff;
      white-space: nowrap;
      margin: 0 auto;
      animation: typing 3.5s steps(40, end), blink-caret .75s step-end infinite;
      width: 0;
    }

    @keyframes typing {
      from { width: 0 }
      to { width: 100% }
    }

    @keyframes blink-caret {
      from, to { border-color: transparent }
      50% { border-color: white; }
    }

    nav ul {
      list-style: none;
      padding: 0;
      text-align: center;
      margin-top: 20px;
    }

    nav ul li {
      display: inline-block;
      margin: 0 15px;
    }

    nav ul li a {
      color: white;
      text-decoration: none;
      font-weight: bold;
      transition: color 0.3s;
    }

    nav ul li a:hover {
      color: #a478e0;
    }

    .section {
      padding: 60px 20px;
      max-width: 1000px;
      margin: auto;
      background: rgba(0, 0, 0, 0.7);
      border-radius: 10px;
      margin-bottom: 40px;
    }

    h2 {
      color: #a478e0;
      font-size: 28px;
      margin-bottom: 20px;
      text-align: center;
    }

    .project-list {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
      gap: 20px;
    }

    .project-card {
      background: rgba(255, 255, 255, 0.05);
      border-radius: 10px;
      height: 200px;
      display: flex;
      align-items: flex-end;
      justify-content: center;
      background-size: cover;
      background-position: center;
      text-align: center;
      transition: transform 0.3s, box-shadow 0.3s;
      position: relative;
    }

    .project-card button {
      background-color: rgba(0, 0, 0, 0.7);
      color: #a478e0;
      border: none;
      padding: 10px 20px;
      font-size: 16px;
      margin-bottom: 20px;
      border-radius: 5px;
      cursor: pointer;
      position: relative;
      z-index: 1;
    }

    .project-card button:hover {
      background-color: #a478e0;
      color: white;
    }

    .tech-stack {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 15px;
      justify-content: center;
    }

    .tech-stack span {
      background-color: #a478e0;
      color: #fff;
      padding: 6px 12px;
      border-radius: 15px;
      font-size: 14px;
      animation: fadeIn 0.5s ease-in-out;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* Tech Tools Section */
    .tech-badges {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 12px;
      margin-top: 20px;
    }

    .tech-badge {
      background: #2b2b2b;
      color: #fff;
      font-weight: bold;
      padding: 12px 16px;
      border-radius: 8px;
      font-size: 14px;
      display: flex;
      align-items: center;
      gap: 8px;
      transition: transform 0.3s ease;
      animation: fadeUp 0.5s ease forwards;
      opacity: 0;
      transform: translateY(15px);
    }

    .tech-badge:hover {
      transform: scale(1.1);
      background: #a478e0;
    }

    .tech-badge img {
      width: 20px;
      height: 20px;
    }

    @keyframes fadeUp {
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    footer {
      text-align: center;
      padding: 20px;
      background: #000;
      color: #ccc;
      font-size: 14px;
    }

    .job-logo {
      width: 100px;
      display: block;
      margin-bottom: 15px;
    }
    #contact a {
  color: #ffffff;
  text-decoration: none;
}

#contact a:hover {
  text-decoration: underline;
}
  </style>
</head>
<body>
  <header>
    <h1>Sri Harsha Mudumba</h1>
    <p class="typing">Machine Learning Engineer | HPC | Systems | AI Infra</p>
    <nav>
      <ul>
        <li><a href="#about">About</a></li>
        <li><a href="#projects">Projects</a></li>
        <li><a href="#tech">Tech Stack</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </nav>
  </header>

  

  <section id="about" class="section">
    <h2>About Me</h2>
    <p>I am a Machine Learning Engineer with a strong foundation in computer engineering and a research-driven mindset focused on optimizing AI systems for performance, scalability, and deployment. With hands-on experience in both academic research and real-world systems, I specialize in building ML pipelines that are efficient, reproducible, and tuned for modern hardware. My graduate work centers on high-performance computing (HPC), inference optimization, and compiler-level ML acceleration, often exploring techniques like quantization, early exits, and model pruning to push the limits of real-time deployment.</p>

<p>I’ve contributed to a range of projects spanning LLM benchmarking, RAG systems, CNN inference optimization, and microarchitecture simulation. These experiences have taught me how to bridge the gap between theory and deployment—from training and evaluating models in PyTorch to compiling and benchmarking them using tools like IREE, ONNX Runtime, and LLVM. Whether it’s deploying a TinyLlama-based retrieval system on local GPUs or compiling 1-bit LLMs for low-latency use cases, I consistently focus on making systems lighter, smarter, and faster.</p>

<p>I am also passionate about open-source development and reproducible ML workflows. I believe in designing with clarity, optimizing with precision, and delivering insights that are actionable and scalable. My long-term goal is to lead efforts in ML systems engineering where research and infrastructure converge to create fast, interpretable, and sustainable AI technologies.</p>
  </section>

  <section id="tech" class="section">
  <h2>🧰 Tech Stack & Tools</h2>
  <div class="tech-badges">
    <!-- Icon-based -->
    <div class="tech-badge" style="animation-delay: 0.1s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" alt="Python" />
      PYTHON
    </div>
    <div class="tech-badge" style="animation-delay: 0.2s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original.svg" alt="PyTorch" />
      PYTORCH
    </div>
    <div class="tech-badge" style="animation-delay: 0.3s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/tensorflow/tensorflow-original.svg" alt="TensorFlow" />
      TENSORFLOW
    </div>
    <div class="tech-badge" style="animation-delay: 0.4s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="Git" />
      GIT
    </div>
    <div class="tech-badge" style="animation-delay: 0.5s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="Linux" />
      LINUX
    </div>
    <div class="tech-badge" style="animation-delay: 0.6s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/oracle/oracle-original.svg" alt="Oracle" />
      ORACLE
    </div>
    <div class="tech-badge" style="animation-delay: 0.7s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/opencv/opencv-original.svg" alt="OpenCV" />
      OPENCV
    </div>
    <!-- Text-only -->
    <div class="tech-badge" style="animation-delay: 0.8s">
      <span>FASTAPI</span>
    </div>
    <div class="tech-badge" style="animation-delay: 0.9s">
      <span>ONNX</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1s">
      <span>IREE</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.1s">
      <span>TRANSFORMERS</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.2s">
      <span>SLURM</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.3s">
      <span>MPI</span>
    </div>
  </div>
</section>


 <section id="projects" class="section">
    <h2>Projects</h2>
    <div class="project-list">
      <div class="project-card" style="background-image:url('LEXA.png');">
        <button onclick="location.href='projects/lexa.html'">LEXA - Lightweight RAG</button>
      </div>
      <div class="project-card" style="background-image:url('1bit.png');">
        <button onclick="location.href='projects/1bitllm.html'">1BitLLM Benchmark</button>
      </div>
      <div class="project-card" style="background-image:url('Snapea_1.png');">
        <button onclick="location.href='projects/snapea.html'">Snapea - Efficient Inference</button>
      </div>
      <div class="project-card" style="background-image:url('Simnet.png');">
        <button onclick="location.href='projects/simnet.html'">SimNet Predictor</button>
      </div>
      <div class="project-card" style="background-image:url('Music.png');">
        <button onclick="location.href='projects/music.html'">Music Genre Classifier</button>
      </div>
      <div class="project-card" style="background-image:url('Number_plate.png');">
        <button onclick="location.href='projects/anpr.html'">Number Plate Detection</button>
      </div>
      <div class="project-card" style="background-image:url('Blockchain.png');">
        <button onclick="location.href='projects/blockchain.html'">Blockchain Insurance</button>
      </div>
    </div>
  </section>
<section id="papers" class="section">
  <h2 style="text-align:center">📚 Paper Review & Research Alignment</h2>
  <div class="scroll-wrapper">
    <div class="scroll-container">
      <!-- Paper 1 -->
      <div class="paper-slide">
        <h3>💡 Memory is the New Compute – And It’s Getting Smarter</h3>
        <p><strong>Paper:</strong> "An Overview of Processing-in-Memory Circuits for AI and ML" (IEEE JETCAS 2022)</p>
        <p>🔹 PIM is no longer science fiction — real SRAM/DRAM/ReRAM-based chips compute directly in memory. Perfect for ML workloads where data movement is the bottleneck.<br>
        🔹 SRAM-PIM enables in-place MACs for fast inference; DRAM-PIM offers high bandwidth; ReRAM-PIM is promising for edge AI due to low power.<br>
        🔹 The paper also covers offloading strategies, runtime scheduling, and cache coherence — integration is tough, but possible.</p>
        <p>📌 <strong>My thesis</strong> explores heterogeneous analog+digital PIM with early exits in deep neural nets to enable:<br>
        ➤ Dynamic resource allocation<br>
        ➤ Reduced energy per inference<br>
        ➤ Smarter entropy-based layer skipping</p>
        <p><strong>TL;DR:</strong> We’re not just moving compute closer to memory — we’re making compute smarter, leaner, and adaptable.</p>
      </div>

      <!-- Paper 2 -->
      <div class="paper-slide">
        <h3>🚀 NeuPIMs: Revolutionizing LLM Inference</h3>
        <p><strong>Why it matters:</strong> LLMs like GPT-4 and LLaMA require high memory bandwidth. NeuPIMs proposes a heterogeneous acceleration design combining NPUs and PIMs.</p>
        <p>🔹 NPUs excel at GEMMs but underperform for GEMVs (bandwidth-heavy).<br>
        🔹 PIMs complement this by handling GEMVs efficiently.<br>
        🔹 NeuPIMs allows <strong>concurrent execution</strong> of GEMMs (via NPU) and GEMVs (via PIM) with:</p>
        <ul>
          <li>✔ Dual row-buffer architecture</li>
          <li>✔ Sub-batch interleaving</li>
          <li>✔ Runtime optimization for throughput</li>
        </ul>
        <p><strong>Results:</strong> Achieved up to <strong>3× higher throughput</strong> than GPU/NPU-only systems — critical for real-time LLM inference at scale.</p>
      </div>

      <!-- Paper 3 -->
      <div class="paper-slide">
        <h3>🧠 Coop: Memory is not a Commodity (NeurIPS 2023)</h3>
        <p>Efficient memory management is crucial for scaling LLMs. This paper presents Coop, a runtime system that reduces fragmentation and improves tensor reuse.</p>
        <p>Key Techniques:</p>
        <ul>
          <li>1️⃣ Sliding window algorithm for low-cost, contiguous memory blocks</li>
          <li>2️⃣ Cheap Tensor Partitioning reduces fragmentation</li>
          <li>3️⃣ Recomputation-based in-place ops reuse memory</li>
        </ul>
        <p><strong>Results:</strong> 35% compute overhead reduction, 30% less fragmentation, 22% latency improvement under tight GPU budgets.</p>
        <p><strong>Limitations:</strong> Hardware-dependent; needs integration with CUDA pools and adaptive tuning. But a major step for exascale training systems.</p>
      </div>
    </div>
  </div>
</section>

<style>
.scroll-wrapper {
  overflow-x: auto;
  white-space: nowrap;
  padding-bottom: 20px;
}

.scroll-container {
  display: flex;
  gap: 20px;
}

.paper-slide {
  flex: 0 0 90%;
  background-color: rgba(255, 255, 255, 0.05);
  padding: 20px;
  border-radius: 12px;
  min-width: 300px;
  max-width: 600px;
  transition: transform 0.3s ease;
  animation: fadeIn 0.8s ease-in-out;
}

.paper-slide:hover {
  transform: scale(1.03);
  background-color: rgba(255, 255, 255, 0.1);
}

@keyframes fadeIn {
  from { opacity: 0; transform: translateY(15px); }
  to { opacity: 1; transform: translateY(0); }
}
</style>


  <!-- Contact -->
  <section id="contact" class="section">
    <h2>Contact</h2>
    <p>Email: <a href="mailto:srim@iastate.edu">srim@iastate.edu</a></p>
    <p>LinkedIn: <a href="https://linkedin.com/in/sriharshamudumba" target="_blank">linkedin.com/in/sriharshamudumba</a></p>
    <p>GitHub: <a href="https://github.com/sriharshamudumba" target="_blank">github.com/sriharshamudumba</a></p>
  </section>

  <footer>
    <p>&copy; 2024 Sri Harsha Mudumba. All rights reserved.</p>
  </footer>
</body>
</html>
  
</body>
</html>
