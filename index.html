<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sri Harsha Mudumba | ML Engineer</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header>
    <h1>Sri Harsha Mudumba</h1>
    <p style="text-align: center; font-size: 20px; font-weight: bold;">Aspiring Machine Learning Engineer</p>
    <p style="text-align: center;">HPC | AI Researcher</p>
    <nav>
      <ul>
        <li><a href="#about">About</a></li>
        <li><a href="#projects">Projects</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#skills">Skills</a></li>
        <li><a href="#paper-reviews">Reviews</a></li>
        <li><a href="#contact">Contact</a></li>
        <li><a href="#resume">Resume</a></li>
      </ul>
    </nav>
  </header>

  <section id="about" class="section">
    <h2>About Me</h2>
    <p>I am a Computer Engineer with a Masterâ€™s focus in <strong>Machine Learning</strong>, <strong>High-Performance Computing (HPC)</strong>, and <strong>Computer Architecture Systems</strong>, driven by a mission to make intelligent systems faster, more scalable, and production-ready.</p>
    <p>Through my graduate work at Iowa State University, Iâ€™ve built a strong foundation across model design, optimization, and deployment. I work at the intersection of AI development and systems engineering to deliver real-world solutions that balance speed, accuracy, and efficiency.</p>
    <p>Previously, I served as an Associate DBA at Cognizant, managing Oracle EBS applications for enterprise clients like Intuit and BioMarin â€” streamlining patching, automation, and performance tuning in production-scale environments.</p>
    <p>I am passionate about bridging AI research with real-world systems deployment and excited to apply my expertise in high-performance, scalable ML engineering.</p>
  </section>

  <section id="experience" class="section">
    <h2>Professional Experience</h2>
    <h3>Associate Database Administrator â€“ Cognizant Technology Solutions</h3>
    <p><strong>Clients:</strong> Intuit, BioMarin</p>
    <ul>
      <li>Maintained Oracle E-Business Suite (11g/12c/19c) environments and optimized mission-critical financial and biomedical systems.</li>
      <li>Performed ADOP patching, database upgrades, and environment cloning for seamless deployments.</li>
      <li>Developed shell scripts to automate patching, alerting, and environment refresh tasks.</li>
      <li>Integrated Active Directory for secure authentication and enforced audit logging policies.</li>
    </ul>
  </section>

  <section id="skills" class="section">
    <h2>Technical Skills</h2>
    <ul>
      <li><strong>Languages:</strong> Python, C++, Shell, SQL</li>
      <li><strong>Frameworks:</strong> PyTorch, TensorFlow, ONNX, EasyOCR, OpenCV</li>
      <li><strong>Tooling:</strong> HuggingFace, FastAPI, Git, Slurm, Oracle EBS</li>
      <li><strong>Domains:</strong> Model Compression, Video Processing, Generative AI, Smart Contracts</li>
      <li><strong>Infra:</strong> Multi-GPU training, HPC clusters, compiler stacks (ONNX/IREE)</li>
    </ul>
  </section>

  <section id="projects" class="section">
    <h2>Projects</h2>
    <div class="project-list">
      <div class="project-card">
        <h3><a href="#lazy-nn">Lazy Neural Network Optimization</a></h3>
        <p>Adaptive early exit mechanism to reduce inference cost using TensorFlow & PyTorch.</p>
      </div>
      <div class="project-card">
        <h3><a href="#1bitllm">1BitLLM Model Benchmarking</a></h3>
        <p>Analyzed quantized LLM performance using ONNX & IREE for low-latency deployment.</p>
      </div>
      <div class="project-card">
        <h3><a href="#snapea">Snapea - Efficient Inference</a></h3>
        <p>Confidence-based skipping and pruning to accelerate CNNs on edge devices.</p>
      </div>
      <div class="project-card">
        <h3><a href="#simnet">SimNet - Architecture Simulation</a></h3>
        <p>Deep learning model to predict microarchitectural behavior and improve simulation throughput.</p>
      </div>
      <div class="project-card">
        <h3><a href="#music-genre">Music Genre Classification</a></h3>
        <p>Used MFCC features and ML models to classify songs by genre in a web interface.</p>
      </div>
      <div class="project-card">
        <h3><a href="#anpr">Automatic Number Plate Recognition</a></h3>
        <p>YOLOv5 + EasyOCR-based ANPR system deployed for traffic and toll monitoring.</p>
      </div>
      <div class="project-card">
        <h3><a href="#ethereum-flight-insurance">Flight Insurance on Blockchain</a></h3>
        <p>Decentralized Ethereum contract to auto-process claims using real-time flight data.</p>
      </div>
    </div>
  </section>

  <section id="paper-reviews" class="section">
    <div class="container">
      <h2 class="section-title">ðŸ“„ Recent Paper Reviews</h2>
      <div class="review-entry">
        <h3>1. Memory is the New Compute</h3>
        <p><strong>Summary:</strong> Based on IEEE JETCAS 2022, it explores SRAM, DRAM, and ReRAM-based PIM circuits, hardware-software co-design, runtime scheduling, and energy savings.</p>
        <p><strong>My Thesis Link:</strong> Early-exit dynamic inference in PIM-based ML pipelines.</p>
      </div>
      <div class="review-entry">
        <h3>2. Early Exit Optimization in Deep Networks</h3>
        <p><strong>Summary:</strong> ResNet50 with entropy-based multi-exit logic to reduce inference time while maintaining accuracy. Achieved 80%+ accuracy at intermediate exits.</p>
      </div>
      <div class="review-entry">
        <h3>3. NeuPIMs for LLM Inference</h3>
        <p><strong>Insight:</strong> Combines NPUs and PIMs using sub-batch interleaving to enhance GEMM/GEMV throughput for LLM workloads. Achieved up to 3Ã— throughput.</p>
      </div>
    </div>
  </section>

  <section id="contact" class="section">
    <h2>Contact</h2>
    <p><strong>Email:</strong> <a href="mailto:srim@iastate.edu">srim@iastate.edu</a></p>
    <p><strong>Phone:</strong> +1 (515)-916-3011</p>
    <p><strong>LinkedIn:</strong> <a href="https://linkedin.com/in/sriharshamudumba" target="_blank">sriharshamudumba</a></p>
    <p><strong>GitHub:</strong> <a href="https://github.com/sriharshamudumba" target="_blank">sriharshamudumba</a></p>
  </section>

  <section id="resume" class="section">
    <h2>Resume</h2>
    <p>Download my latest resume:
      <a href="Sriharsha_Mudumba_resume_apple.pdf" target="_blank" style="font-weight: bold; color: #a478e0;">
        Click Here
      </a>
    </p>
  </section>

  <footer>
    <p>&copy; 2024 Sri Harsha Mudumba. All rights reserved.</p>
  </footer>
</body>
</html>
