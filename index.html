<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sri Harsha Mudumba - Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Sri Harsha Mudumba</h1>
        <p>Machine Learning Engineer | HPC | AI Researcher</p>
        <nav>
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#projects">Projects</a></li>
                <li><a href="#skills">Skills</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>
    </header>
    
    <section id="about">
        <h2>About Me</h2>
        <p>I am currently pursuing a Masterâ€™s in Computer Engineering at Iowa State University, with a strong passion for Artificial Intelligence, Machine Learning, High-Performance Computing (HPC), and Distributed Systems. My research interests include optimizing deep learning models, designing scalable AI architectures, and accelerating inference in real-world applications.</p>
        <p>I have hands-on experience with leading AI frameworks such as TensorFlow, PyTorch, and ONNX, and I specialize in model compression, quantization, and performance benchmarking. My expertise extends to working with large-scale data processing pipelines, parallel computing with OpenMP and MPI, and cloud-based AI deployments.</p>
        <p>Beyond my academic and professional endeavors, I actively contribute to open-source projects, participate in AI research, and collaborate with teams to build intelligent, scalable, and efficient machine learning solutions. I am driven by the challenge of pushing AI systems to their maximum potential while maintaining efficiency and usability.</p>
    </section>
    
    <section id="projects">
        <h2>Projects</h2>
        <div class="project">
            <h3>Lazy Neural Network Optimization</h3>
            <p><strong>What is it?</strong> This project focuses on optimizing neural network inference by implementing adaptive early exit mechanisms. By analyzing intermediate activations, we can reduce redundant computations, improving efficiency without sacrificing accuracy.</p>
            <ul>
                <li>Dynamic confidence-based early exits to reduce computation time.</li>
                <li>Reduction in model latency while maintaining high prediction accuracy.</li>
                <li>Implemented using TensorFlow and PyTorch with custom optimization layers.</li>
            </ul>
            <p><strong>GitHub Repository:</strong> <a href="https://github.com/sriharshamudumba/Lazy-NN-Optimization" target="_blank" style="color: white;">Lazy NN Optimization</a></p>
        </div>
        <div class="project">
            <h3>Benchmarking 1BitLLM</h3>
            <p><strong>What is it?</strong> This project systematically evaluates the performance of 1BitLLM models under various computing environments using ONNX and IREE compilers, providing insights into hardware compatibility, optimization techniques, and deployment efficiency.</p>
            <ul>
                <li>Performance benchmarking across multiple hardware configurations (CPU, GPU, TPU).</li>
                <li>Latency and memory footprint analysis for efficient AI model deployment.</li>
                <li>Implementation of quantization-aware training for reduced model size.</li>
            </ul>
            <p><strong>GitHub Repository:</strong> <a href="https://github.com/sriharshamudumba/1BitLLM-Benchmarking" target="_blank" style="color: white;">1BitLLM Benchmarking</a></p>
        </div>
    </section>
    
    <section id="skills">
        <h2>Technical Skills</h2>
        <ul>
            <li><strong>Programming:</strong> Python, C++, SQL, Shell scripting</li>
            <li><strong>AI Frameworks:</strong> TensorFlow, PyTorch, ONNX</li>
            <li><strong>HPC:</strong> OpenMP, MPI, Slurm</li>
            <li><strong>Databases:</strong> Oracle 11g/12c/19c</li>
            <li><strong>Cloud Platforms:</strong> AWS, Google Cloud, Microsoft Azure</li>
            <li><strong>Model Optimization:</strong> Quantization, Pruning, Tensor Decomposition</li>
        </ul>
    </section>
    
    <section id="contact">
        <h2>Contact</h2>
        <p>Email: <a href="mailto:srim@iastate.edu" style="color: white;">srim@iastate.edu</a></p>
        <p>LinkedIn: <a href="https://www.linkedin.com/in/sriharshamudumba" target="_blank" style="color: white;">sriharshamudumba</a></p>
        <p>GitHub: <a href="https://github.com/sriharshamudumba" target="_blank" style="color: white;">sriharshamudumba</a></p>
    </section>
    
    <footer>
        <p>&copy; 2024 Sri Harsha Mudumba. All rights reserved.</p>
    </footer>
</body>
</html>
