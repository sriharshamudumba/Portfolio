<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sri Harsha Mudumba | ML Engineer</title>
  <link rel="stylesheet" href="styles.css" />
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap');

    body {
      font-family: 'Poppins', sans-serif;
      margin: 0;
      padding: 0;
      background: url('ml.png') no-repeat center center fixed;
      background-size: cover;
      color: white;
      scroll-behavior: smooth;
      position: relative;
      z-index: 0;
    }

    body::before {
      content: "";
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      background: rgba(0, 0, 0, 0.75);
      z-index: -1;
    }

    header {
      background: transparent;
      color: white;
      text-align: center;
      padding: 40px 20px;
      box-shadow: 0 4px 10px rgba(255, 255, 255, 0.1);
      position: relative;
    }

    .typing {
      font-size: 20px;
      font-weight: bold;
      border-right: 2px solid #fff;
      white-space: nowrap;
      overflow: hidden;
      width: fit-content;
      animation: typing 3.5s steps(40, end) forwards;
      margin: 10px auto;
    }

    @keyframes typing {
      from { width: 0; }
      to { width: 100%; }
    }

    nav ul {
      list-style: none;
      padding: 0;
      text-align: center;
      margin-top: 20px;
    }

    nav ul li {
      display: inline-block;
      margin: 0 15px;
    }

    nav ul li a {
      color: white;
      text-decoration: none;
      font-weight: bold;
      transition: color 0.3s;
    }

    nav ul li a:hover {
      color: #a478e0;
    }

    .section {
      padding: 60px 20px;
      max-width: 1000px;
      margin: auto;
      background-color: rgba(0, 0, 0, 0.6);
      border-radius: 12px;
      margin-bottom: 30px;
    }

    h2 {
      color: #a478e0;
      font-size: 28px;
      margin-bottom: 20px;
      text-align: center;
    }

    .project-list {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
      gap: 20px;
    }

    .project-card {
      background: rgba(255, 255, 255, 0.08);
      padding: 20px;
      border-radius: 10px;
      text-align: center;
      box-shadow: 0 2px 10px rgba(255, 255, 255, 0.1);
      transition: transform 0.3s, box-shadow 0.3s;
      background-size: cover;
      background-position: center;
      color: white;
      height: 200px;
      display: flex;
      align-items: flex-end;
      justify-content: center;
      position: relative;
    }

    .project-card::after {
      content: '';
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      background: rgba(0,0,0,0.4);
      border-radius: 10px;
      z-index: 0;
    }

    .project-card button {
      position: relative;
      z-index: 1;
      background-color: rgba(0, 0, 0, 0.6);
      color: #a478e0;
      border: none;
      padding: 10px 20px;
      font-size: 16px;
      border-radius: 5px;
      cursor: pointer;
      transition: background 0.3s;
    }

    .project-card button:hover {
      background-color: #a478e0;
      color: white;
    }

    .project-card:hover {
      transform: scale(1.05);
      box-shadow: 0 0 15px rgba(255, 255, 255, 0.2);
    }

    .project-card h3 a {
      color: #a478e0;
      text-decoration: none;
    }

    .tech-badge {
      background: #333;
      color: white;
      padding: 10px 18px;
      border-radius: 6px;
      display: flex;
      align-items: center;
      gap: 10px;
      font-weight: 600;
      font-size: 14px;
      transition: transform 0.3s ease-in-out;
      opacity: 0;
      transform: translateY(15px);
      animation: fadeUp 0.5s forwards;
    }

    .tech-badge:hover {
      transform: scale(1.1);
      background: #a478e0;
    }

    @keyframes fadeUp {
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    #contact a {
      color: #ffffff;
      text-decoration: none;
    }

    #contact a:hover {
      text-decoration: underline;
    }

    .scroll-wrapper {
      overflow-x: auto;
      white-space: nowrap;
      padding-bottom: 20px;
    }

    .scroll-container {
      display: flex;
      flex-wrap: nowrap;
      gap: 20px;
      padding: 10px;
    }

    .paper-slide {
      flex: 0 0 auto;
      background-color: rgba(255, 255, 255, 0.08);
      padding: 20px;
      border-radius: 12px;
      min-width: 320px;
      max-width: 500px;
      height: auto;
      box-sizing: border-box;
      white-space: normal;
      overflow: hidden;
      color: white;
      line-height: 1.6;
      word-wrap: break-word;
      overflow-wrap: break-word;
      transition: transform 0.3s ease;
      animation: fadeIn 0.8s ease-in-out;
    }

    .paper-slide:hover {
      transform: scale(1.03);
      background-color: rgba(255, 255, 255, 0.1);
    }

    footer {
      text-align: center;
      padding: 20px;
      background: #000;
      color: #ccc;
      font-size: 14px;
    }

    .job-logo {
      width: 100px;
      display: block;
      margin-bottom: 15px;
    }
  </style>
</head>
<body><body>
  <header>
    <h1>Sri Harsha Mudumba</h1>
    <p class="typing">Aspiring ML Engineer | HPC | AI Models | Model Optimization </p>

    <nav>
      <ul>
        <li><a href="#about">About</a></li>
        <li><a href="#projects">Projects</a></li>
        <li><a href="#tech">Tech Stack</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#papers">Paper Review</a></li>
       <li><a href="#contact">Contact</a></li>
      </ul>
    </nav>
  </header>

  

  <section id="about" class="section">
    <h2>About Me</h2>
    <p>I am a Machine Learning Engineer with a strong foundation in computer engineering and a research-driven mindset focused on optimizing AI systems for performance, scalability, and deployment. With hands-on experience in both academic research and real-world systems, I specialize in building ML pipelines that are efficient, reproducible, and tuned for modern hardware. My graduate work centers on high-performance computing (HPC), inference optimization, and compiler-level ML acceleration, often exploring techniques like quantization, early exits, and model pruning to push the limits of real-time deployment.</p>

<p>I‚Äôve contributed to a range of projects spanning LLM benchmarking, RAG systems, CNN inference optimization, and microarchitecture simulation. These experiences have taught me how to bridge the gap between theory and deployment‚Äîfrom training and evaluating models in PyTorch to compiling and benchmarking them using tools like IREE, ONNX Runtime, and LLVM. Whether it‚Äôs deploying a TinyLlama-based retrieval system on local GPUs or compiling 1-bit LLMs for low-latency use cases, I consistently focus on making systems lighter, smarter, and faster.</p>

<p>I am also passionate about open-source development and reproducible ML workflows. I believe in designing with clarity, optimizing with precision, and delivering insights that are actionable and scalable. My long-term goal is to lead efforts in ML systems engineering where research and infrastructure converge to create fast, interpretable, and sustainable AI technologies.</p>
  </section>

  <section id="tech" class="section">
  <h2>üß∞ Tech Stack & Tools</h2>
  <div class="tech-badges">
    <!-- Icon-based -->
    <div class="tech-badge" style="animation-delay: 0.1s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" alt="Python" />
      PYTHON
    </div>
    <div class="tech-badge" style="animation-delay: 0.2s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original.svg" alt="PyTorch" />
      PYTORCH
    </div>
    <div class="tech-badge" style="animation-delay: 0.3s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/tensorflow/tensorflow-original.svg" alt="TensorFlow" />
      TENSORFLOW
    </div>
    <div class="tech-badge" style="animation-delay: 0.4s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="Git" />
      GIT
    </div>
    <div class="tech-badge" style="animation-delay: 0.5s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="Linux" />
      LINUX
    </div>
    <div class="tech-badge" style="animation-delay: 0.6s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/oracle/oracle-original.svg" alt="Oracle" />
      ORACLE
    </div>
    <div class="tech-badge" style="animation-delay: 0.7s">
      <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/opencv/opencv-original.svg" alt="OpenCV" />
      OPENCV
    </div>
    <!-- Text-only -->
    <div class="tech-badge" style="animation-delay: 0.8s">
      <span>FASTAPI</span>
    </div>
    <div class="tech-badge" style="animation-delay: 0.9s">
      <span>ONNX</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1s">
      <span>IREE</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.1s">
      <span>TRANSFORMERS</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.2s">
      <span>SLURM</span>
    </div>
    <div class="tech-badge" style="animation-delay: 1.3s">
      <span>MPI</span>
    </div>
  </div>
</section>


  <!-- Project section with external links -->
  <section id="projects" class="section">
    <h2>Projects</h2>
    <div class="project-list">
      <div class="project-card" style="background-image:url('Lexa.png');">
        <button onclick="location.href='projects/lexa.html'">LEXA - Lightweight RAG</button>
      </div>
      <div class="project-card" style="background-image:url('1bit.png');">
        <button onclick="location.href='projects/1bitllm.html'">1BitLLM Benchmark</button>
      </div>
      <div class="project-card" style="background-image:url('Snapea_1.png');">
        <button onclick="location.href='projects/snapea.html'">Snapea - Efficient Inference</button>
      </div>
      <div class="project-card" style="background-image:url('Simnet.png');">
        <button onclick="location.href='projects/simnet.html'">SimNet Predictor</button>
      </div>
      <div class="project-card" style="background-image:url('Music.png');">
        <button onclick="location.href='projects/music.html'">Music Genre Classifier</button>
      </div>
      <div class="project-card" style="background-image:url('Number_plate.png');">
        <button onclick="location.href='projects/anpr.html'">Number Plate Detection</button>
      </div>
      <div class="project-card" style="background-image:url('Blockchain.png');">
        <button onclick="location.href='projects/blockchain.html'">Blockchain Insurance</button>
      </div>
    </div>
  </section>

  <!-- Work Experience -->
  <section id="experience" class="section">
    <h2>Professional Experience</h2>
    <img src="CTS_image.jpg" alt="CTSS Logo" class="job-logo"/>
    <h3>Associate Database Administrator ‚Äì Cognizant Technology Solutions</h3>
    <ul>
      <li>Maintained Oracle EBS environments for clients like Intuit and BioMarin</li>
      <li>Automated patching and upgrades using Shell scripts</li>
      <li>Managed cloning, user-role audits, and SOX compliance</li>
    </ul>
  </section>
<section id="papers" class="section">
  <h2 style="text-align:center">üìö Paper Reviews </h2>
  <div class="scroll-wrapper">
    <div class="scroll-container">
      <!-- Paper 1 -->
      <div class="paper-slide">
        <h3>üí° Memory is the New Compute ‚Äì And It‚Äôs Getting Smarter</h3>
        <p><strong>Paper:</strong> "An Overview of Processing-in-Memory Circuits for AI and ML" (IEEE JETCAS 2022)</p>
        <p>üîπ PIM is no longer science fiction ‚Äî real SRAM/DRAM/ReRAM-based chips compute directly in memory. Perfect for ML workloads where data movement is the bottleneck.<br>
        üîπ SRAM-PIM enables in-place MACs for fast inference; DRAM-PIM offers high bandwidth; ReRAM-PIM is promising for edge AI due to low power.<br>
        üîπ The paper also covers offloading strategies, runtime scheduling, and cache coherence ‚Äî integration is tough, but possible.</p>
        <p>üìå <strong>My thesis</strong> explores heterogeneous analog+digital PIM with early exits in deep neural nets to enable:<br>
        ‚û§ Dynamic resource allocation<br>
        ‚û§ Reduced energy per inference<br>
        ‚û§ Smarter entropy-based layer skipping</p>
        <p><strong>TL;DR:</strong> We‚Äôre not just moving compute closer to memory ‚Äî we‚Äôre making compute smarter, leaner, and adaptable.</p>
      </div>

      <!-- Paper 2 -->
      <div class="paper-slide">
        <h3>üöÄ NeuPIMs: Revolutionizing LLM Inference</h3>
        <p><strong>Why it matters:</strong> LLMs like GPT-4 and LLaMA require high memory bandwidth. NeuPIMs proposes a heterogeneous acceleration design combining NPUs and PIMs.</p>
        <p>üîπ NPUs excel at GEMMs but underperform for GEMVs (bandwidth-heavy).<br>
        üîπ PIMs complement this by handling GEMVs efficiently.<br>
        üîπ NeuPIMs allows <strong>concurrent execution</strong> of GEMMs (via NPU) and GEMVs (via PIM) with:</p>
        <ul>
          <li>‚úî Dual row-buffer architecture</li>
          <li>‚úî Sub-batch interleaving</li>
          <li>‚úî Runtime optimization for throughput</li>
        </ul>
        <p><strong>Results:</strong> Achieved up to <strong>3√ó higher throughput</strong> than GPU/NPU-only systems ‚Äî critical for real-time LLM inference at scale.</p>
      </div>

      <!-- Paper 3 -->
      <div class="paper-slide">
        <h3>üß† Coop: Memory is not a Commodity (NeurIPS 2023)</h3>
        <p>Efficient memory management is crucial for scaling LLMs. This paper presents Coop, a runtime system that reduces fragmentation and improves tensor reuse.</p>
        <p>Key Techniques:</p>
        <ul>
          <li>1Ô∏è‚É£ Sliding window algorithm for low-cost, contiguous memory blocks</li>
          <li>2Ô∏è‚É£ Cheap Tensor Partitioning reduces fragmentation</li>
          <li>3Ô∏è‚É£ Recomputation-based in-place ops reuse memory</li>
        </ul>
        <p><strong>Results:</strong> 35% compute overhead reduction, 30% less fragmentation, 22% latency improvement under tight GPU budgets.</p>
        <p><strong>Limitations:</strong> Hardware-dependent; needs integration with CUDA pools and adaptive tuning. But a major step for exascale training systems.</p>
      </div>
    </div>
  </div>
</section>

  <!-- Contact -->
  <section id="contact" class="section">
    <h2>Contact</h2>
    <p>Email: <a href="mailto:srim@iastate.edu">srim@iastate.edu</a></p>
    <p>LinkedIn: <a href="https://linkedin.com/in/sriharshamudumba" target="_blank">linkedin.com/in/sriharshamudumba</a></p>
    <p>GitHub: <a href="https://github.com/sriharshamudumba" target="_blank">github.com/sriharshamudumba</a></p>
  </section>

  <footer>
    <p>&copy; 2024 Sri Harsha Mudumba. All rights reserved.</p>
  </footer>
</body>
</html>
